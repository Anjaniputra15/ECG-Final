{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# 🫀 ECG-LLM Complete Training Pipeline on Google Colab Pro\n",
        "\n",
        "This notebook adapts your existing ECG-LLM codebase for training on Google Colab Pro with the PTB-XL dataset.\n",
        "\n",
        "**Features:**\n",
        "- Bootstrap R-peak detection training\n",
        "- Advanced multi-model ensemble\n",
        "- Google Drive integration for persistence\n",
        "- PTB-XL dataset (21,837 clinical ECG records)\n",
        "- Optimized for Colab Pro GPU resources\n",
        "\n",
        "**Requirements:** Colab Pro subscription with GPU runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 🔧 Step 1: Environment Setup & GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gpu_check",
        "outputId": "f552555f-c236-4ad1-8b3b-8874c2046f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug  7 22:12:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "🔥 PyTorch version: 2.6.0+cu118\n",
            "🖥️  CUDA available: True\n",
            "🚀 GPU: Tesla T4\n",
            "💾 GPU Memory: 15.8 GB\n",
            "\n",
            "💽 Available Storage:\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "/dev/root       2.0G  1.2G  775M  61% /usr/sbin/docker-init\n"
          ]
        }
      ],
      "source": [
        "# Check GPU and Colab Pro status\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\n🔥 PyTorch version: {torch.__version__}\")\n",
        "print(f\"🖥️  CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"🚀 GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Check available disk space\n",
        "print(\"\\n💽 Available Storage:\")\n",
        "!df -h | grep -E '/dev/root|Filesystem'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install"
      },
      "source": [
        "## 📦 Step 2: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "install_deps",
        "outputId": "34732a89-5754-4152-a725-07ae24c5e5fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: neurokit2 in /usr/local/lib/python3.11/dist-packages (0.2.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.16.1)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from neurokit2) (1.6.1)\n",
            "Requirement already satisfied: PyWavelets>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from neurokit2) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->neurokit2) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.3.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu118)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\n",
            "Collecting efficientnet-pytorch\n",
            "  Using cached efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.34.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=99d4e82dc68e7cc0a8939c102219a5eb2d92a31b10c585d61dff3a75385cbc44\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\n",
            "\n",
            "✅ All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install wfdb neurokit2 pandas numpy matplotlib seaborn\n",
        "!pip install opencv-python scikit-learn tqdm\n",
        "!pip install transformers datasets accelerate\n",
        "!pip install timm efficientnet-pytorch\n",
        "!pip install Pillow\n",
        "\n",
        "print(\"\\n✅ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drive_setup"
      },
      "source": [
        "## 🗂️ Step 3: Setup Google Drive Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive",
        "outputId": "170ba90f-4b35-432b-cbf1-e07a95adb6ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for persistent storage\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project structure in Drive\n",
        "drive_project_path = \"/content/drive/MyDrive/ECG_LLM_Project\"\n",
        "project_dirs = [\n",
        "    f\"{drive_project_path}/models\",\n",
        "    f\"{drive_project_path}/checkpoints\",\n",
        "    f\"{drive_project_path}/results\",\n",
        "    f\"{drive_project_path}/data\"\n",
        "]\n",
        "\n",
        "for directory in project_dirs:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    print(f\"✅ Created: {directory}\")\n",
        "\n",
        "print(\"🎉 Google Drive integration complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project_setup"
      },
      "source": [
        "## 📁 Step 4: Setup Project Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_project"
      },
      "outputs": [],
      "source": [
        "# Create local project structure\n",
        "import os\n",
        "print(\"Creating ECG-LLM project structure...\")\n",
        "\n",
        "# Create main project folder\n",
        "os.makedirs('ECG_Project', exist_ok=True)\n",
        "os.chdir('ECG_Project')\n",
        "\n",
        "# Create subfolders matching your original structure\n",
        "folders = [\n",
        "    'data',\n",
        "    'models/backbones',\n",
        "    'training',\n",
        "    'experiments',\n",
        "    'results'\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    print(f\"✅ Created folder: {folder}\")\n",
        "\n",
        "print(\"🎯 Project structure ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_download"
      },
      "source": [
        "## 📥 Step 5: Download PTB-XL Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_data"
      },
      "outputs": [],
      "source": [
        "# Download PTB-XL dataset\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"📥 Starting download of PTB-XL dataset...\")\n",
        "print(\"This will take 5-10 minutes - please be patient!\")\n",
        "\n",
        "# Dataset URL\n",
        "url = \"https://physionet.org/static/published-projects/ptb-xl/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip\"\n",
        "\n",
        "try:\n",
        "    # Download the file\n",
        "    print(\"Downloading... (no progress bar, just wait)\")\n",
        "    urllib.request.urlretrieve(url, \"ptb-xl-dataset.zip\")\n",
        "\n",
        "    # Check file size\n",
        "    size_mb = os.path.getsize(\"ptb-xl-dataset.zip\") / (1024 * 1024)\n",
        "    print(f\"✅ Download complete! File size: {size_mb:.1f} MB\")\n",
        "\n",
        "    # Extract dataset\n",
        "    print(\"📦 Extracting dataset...\")\n",
        "    with zipfile.ZipFile(\"ptb-xl-dataset.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"data/\")\n",
        "\n",
        "    print(\"✅ Extraction complete!\")\n",
        "\n",
        "    # Verify extraction\n",
        "    dataset_path = \"data/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\"\n",
        "    if os.path.exists(dataset_path):\n",
        "        print(f\"✅ Dataset extracted to: {dataset_path}\")\n",
        "\n",
        "        # Check key files\n",
        "        key_files = [\"ptbxl_database.csv\", \"scp_statements.csv\"]\n",
        "        for file in key_files:\n",
        "            if os.path.exists(f\"{dataset_path}/{file}\"):\n",
        "                print(f\"✅ Found: {file}\")\n",
        "            else:\n",
        "                print(f\"❌ Missing: {file}\")\n",
        "\n",
        "    # Clean up zip file to save space\n",
        "    os.remove(\"ptb-xl-dataset.zip\")\n",
        "    print(\"🧹 Cleaned up zip file\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Download failed: {e}\")\n",
        "    print(\"Please check your internet connection and try again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_explore"
      },
      "source": [
        "## 📊 Step 6: Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_data"
      },
      "outputs": [],
      "source": [
        "# Explore PTB-XL dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load database\n",
        "dataset_path = \"data/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\"\n",
        "database = pd.read_csv(f\"{dataset_path}/ptbxl_database.csv\", index_col='ecg_id')\n",
        "statements = pd.read_csv(f\"{dataset_path}/scp_statements.csv\", index_col=0)\n",
        "\n",
        "print(f\"📊 PTB-XL Dataset Overview:\")\n",
        "print(f\"  Total ECG records: {len(database):,}\")\n",
        "print(f\"  Age range: {database.age.min():.0f} - {database.age.max():.0f} years\")\n",
        "print(f\"  Male patients: {(database.sex == 0).sum():,}\")\n",
        "print(f\"  Female patients: {(database.sex == 1).sum():,}\")\n",
        "print(f\"  Sampling frequencies: {database.fs.value_counts().to_dict()}\")\n",
        "\n",
        "# Visualize data distribution\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "# Age distribution\n",
        "axes[0, 0].hist(database.age.dropna(), bins=30, alpha=0.7, color='blue')\n",
        "axes[0, 0].set_title('Age Distribution')\n",
        "axes[0, 0].set_xlabel('Age')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "\n",
        "# Sex distribution\n",
        "sex_counts = database.sex.value_counts()\n",
        "axes[0, 1].pie(sex_counts.values, labels=['Male', 'Female'], autopct='%1.1f%%')\n",
        "axes[0, 1].set_title('Sex Distribution')\n",
        "\n",
        "# Sampling frequency\n",
        "fs_counts = database.fs.value_counts()\n",
        "axes[1, 0].bar(fs_counts.index.astype(str), fs_counts.values, color='green', alpha=0.7)\n",
        "axes[1, 0].set_title('Sampling Frequency Distribution')\n",
        "axes[1, 0].set_xlabel('Sampling Rate (Hz)')\n",
        "axes[1, 0].set_ylabel('Count')\n",
        "\n",
        "# Recording length distribution\n",
        "axes[1, 1].hist(database.length_s.dropna(), bins=30, alpha=0.7, color='red')\n",
        "axes[1, 1].set_title('Recording Length Distribution')\n",
        "axes[1, 1].set_xlabel('Length (seconds)')\n",
        "axes[1, 1].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('dataset_overview.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n📈 Dataset visualization saved as 'dataset_overview.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colab_training_code"
      },
      "source": [
        "## 🧠 Step 7: Load ECG-LLM Training Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_colab_training"
      },
      "outputs": [],
      "source": [
        "# Create the Colab-adapted training code\n",
        "# This adapts your existing bootstrap_trainer.py and advanced_trainer.py for Colab\n",
        "\n",
        "colab_training_code = '''\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Google Colab Training Pipeline for ECG-LLM PQRST Detection\n",
        "Adapted from existing codebase for Colab Pro environment with PTB-XL dataset\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import os\n",
        "import wfdb\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ColabECGConfig:\n",
        "    \"\"\"Configuration optimized for Google Colab Pro\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Colab-optimized settings\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.batch_size = 16  # Optimized for Colab GPU memory\n",
        "        self.learning_rate = 1e-4\n",
        "        self.num_epochs = 50  # Reasonable for Colab session limits\n",
        "        self.warmup_epochs = 5\n",
        "        self.weight_decay = 1e-4\n",
        "        self.gradient_clip_norm = 1.0\n",
        "        self.save_every_n_epochs = 10\n",
        "\n",
        "        # Data settings\n",
        "        self.max_samples_per_split = 1000  # Start with subset for faster training\n",
        "        self.signal_length = 5000  # 10 seconds at 500Hz\n",
        "        self.num_leads = 12\n",
        "        self.num_classes = 6  # P, Q, R, S, T, Background\n",
        "\n",
        "        # Google Drive integration\n",
        "        self.use_drive = True\n",
        "        self.drive_project_path = \"/content/drive/MyDrive/ECG_LLM_Project\"\n",
        "\n",
        "        print(f\"🔧 Colab ECG Config Initialized\")\n",
        "        print(f\"🖥️  Device: {self.device}\")\n",
        "        print(f\"📦 Batch size: {self.batch_size}\")\n",
        "        print(f\"🎯 Max samples per split: {self.max_samples_per_split}\")\n",
        "\n",
        "# ... [Rest of the training code would be loaded here]\n",
        "'''\n",
        "\n",
        "# Write the training code to a file\n",
        "with open('colab_training.py', 'w') as f:\n",
        "    f.write(colab_training_code)\n",
        "\n",
        "print(\"📝 Colab training code template created\")\n",
        "print(\"Now loading the complete training pipeline...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_complete_training"
      },
      "outputs": [],
      "source": [
        "# Load the complete training pipeline\n",
        "# Copy and paste your complete colab_training.py content here\n",
        "\n",
        "exec(open('/content/ECG_Project/colab_training.py').read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_models"
      },
      "source": [
        "## 📤 Step 8: Upload Your Model Files (Optional)\n",
        "\n",
        "**Option A: Upload via File Browser**\n",
        "1. Click the 📁 Files tab on the left sidebar\n",
        "2. Navigate to `/content/ECG_Project/models/backbones/`\n",
        "3. Upload your model files:\n",
        "   - `vision_transformer_ecg.py`\n",
        "   - `multimodal_ecg.py`  \n",
        "   - `hubert_ecg.py`\n",
        "   - `maskrcnn_ecg.py`\n",
        "\n",
        "**Option B: Use the cell below to upload automatically**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_files"
      },
      "outputs": [],
      "source": [
        "# Upload model files from your computer\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print(\"📤 Upload your ECG model files here:\")\n",
        "print(\"Select files like: bootstrap_trainer.py, vision_transformer_ecg.py, etc.\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to appropriate directories\n",
        "for filename, content in uploaded.items():\n",
        "    if filename.endswith('trainer.py'):\n",
        "        shutil.move(filename, f'training/{filename}')\n",
        "        print(f\"✅ Moved {filename} to training/\")\n",
        "    elif filename.endswith('_ecg.py') or 'model' in filename:\n",
        "        shutil.move(filename, f'models/backbones/{filename}')\n",
        "        print(f\"✅ Moved {filename} to models/backbones/\")\n",
        "    else:\n",
        "        print(f\"📁 Kept {filename} in root directory\")\n",
        "\n",
        "print(\"🎉 File upload complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "start_training"
      },
      "source": [
        "## 🚀 Step 9: Start Training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_training"
      },
      "outputs": [],
      "source": [
        "# Run the complete training pipeline\n",
        "print(\"🫀 Starting ECG-LLM Training on Google Colab Pro!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# This will execute your adapted training code\n",
        "try:\n",
        "    # Initialize and run training\n",
        "    trainer, history = run_colab_training()\n",
        "\n",
        "    print(\"\\n🎉 Training completed successfully!\")\n",
        "    print(f\"📊 Final results:\")\n",
        "    print(f\"  Best validation loss: {min(history['val_loss']):.4f}\")\n",
        "    print(f\"  Best accuracy: {max(history['binary_acc']):.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Training failed: {e}\")\n",
        "    print(\"Please check the error and try again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "monitor_training"
      },
      "source": [
        "## 📈 Step 10: Monitor Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "monitor"
      },
      "outputs": [],
      "source": [
        "# Monitor GPU usage during training\n",
        "!watch -n 1 nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_results"
      },
      "outputs": [],
      "source": [
        "# Plot training results (run after training completes)\n",
        "if 'trainer' in locals() and hasattr(trainer, 'training_history'):\n",
        "    trainer.plot_training_curves()\n",
        "else:\n",
        "    print(\"⚠️  Training not completed yet or trainer not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_model"
      },
      "source": [
        "## 🧪 Step 11: Test the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_inference"
      },
      "outputs": [],
      "source": [
        "# Test model inference\n",
        "if 'trainer' in locals():\n",
        "    print(\"🧪 Testing trained model...\")\n",
        "\n",
        "    # Load a sample ECG for testing\n",
        "    sample_ecg_id = 1  # First ECG in dataset\n",
        "\n",
        "    try:\n",
        "        # Load sample ECG\n",
        "        record_path = f\"{dataset_path}/records500/{sample_ecg_id:05d}/{sample_ecg_id:05d}\"\n",
        "        signal, fields = wfdb.rdsamp(record_path)\n",
        "\n",
        "        # Preprocess for model\n",
        "        signal_tensor = torch.FloatTensor(signal.T[:12])  # First 12 leads\n",
        "\n",
        "        # Pad/truncate to expected length\n",
        "        if signal_tensor.shape[1] > 5000:\n",
        "            signal_tensor = signal_tensor[:, :5000]\n",
        "        else:\n",
        "            padding = 5000 - signal_tensor.shape[1]\n",
        "            signal_tensor = F.pad(signal_tensor, (0, padding))\n",
        "\n",
        "        # Add batch dimension and move to device\n",
        "        signal_tensor = signal_tensor.unsqueeze(0).to(trainer.device)\n",
        "\n",
        "        # Run inference\n",
        "        trainer.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = trainer.model(signal_tensor)\n",
        "\n",
        "        # Display results\n",
        "        binary_pred = outputs['binary_logits'].softmax(dim=1)\n",
        "        print(f\"\\n🔍 Sample ECG {sample_ecg_id} Results:\")\n",
        "        print(f\"  Normal probability: {binary_pred[0, 0]:.3f}\")\n",
        "        print(f\"  Abnormal probability: {binary_pred[0, 1]:.3f}\")\n",
        "        print(f\"  Prediction: {'Normal' if binary_pred[0, 0] > 0.5 else 'Abnormal'}\")\n",
        "\n",
        "        # Plot ECG and prediction\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # Plot first 4 leads\n",
        "        for i in range(4):\n",
        "            plt.subplot(2, 2, i+1)\n",
        "            plt.plot(signal_tensor[0, i].cpu().numpy())\n",
        "            plt.title(f'Lead {i+1}')\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('sample_ecg_prediction.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"✅ Model testing complete!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Testing failed: {e}\")\n",
        "else:\n",
        "    print(\"⚠️  Model not available. Please run training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_results"
      },
      "source": [
        "## 💾 Step 12: Save and Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "package_results"
      },
      "outputs": [],
      "source": [
        "# Package all results for download\n",
        "import zipfile\n",
        "import json\n",
        "\n",
        "print(\"📦 Packaging training results...\")\n",
        "\n",
        "# Create results archive\n",
        "with zipfile.ZipFile('ecg_llm_training_results.zip', 'w') as zipf:\n",
        "\n",
        "    # Add model files\n",
        "    model_files = ['best_model.pth']\n",
        "    for model_file in model_files:\n",
        "        if os.path.exists(model_file):\n",
        "            zipf.write(model_file)\n",
        "            print(f\"✅ Added {model_file}\")\n",
        "\n",
        "    # Add checkpoints\n",
        "    checkpoint_files = [f for f in os.listdir('.') if f.startswith('checkpoint_epoch_')]\n",
        "    if checkpoint_files:\n",
        "        latest_checkpoint = sorted(checkpoint_files)[-1]\n",
        "        zipf.write(latest_checkpoint)\n",
        "        print(f\"✅ Added {latest_checkpoint}\")\n",
        "\n",
        "    # Add plots and visualizations\n",
        "    plot_files = ['training_curves.png', 'dataset_overview.png', 'sample_ecg_prediction.png']\n",
        "    for plot_file in plot_files:\n",
        "        if os.path.exists(plot_file):\n",
        "            zipf.write(plot_file)\n",
        "            print(f\"✅ Added {plot_file}\")\n",
        "\n",
        "    # Save training history\n",
        "    if 'trainer' in locals() and hasattr(trainer, 'training_history'):\n",
        "        with open('training_history.json', 'w') as f:\n",
        "            json.dump(trainer.training_history, f, indent=2)\n",
        "        zipf.write('training_history.json')\n",
        "        print(f\"✅ Added training_history.json\")\n",
        "\n",
        "    # Add configuration\n",
        "    if 'config' in locals():\n",
        "        config_dict = {k: v for k, v in config.__dict__.items() if not k.startswith('_')}\n",
        "        with open('training_config.json', 'w') as f:\n",
        "            json.dump(config_dict, f, indent=2)\n",
        "        zipf.write('training_config.json')\n",
        "        print(f\"✅ Added training_config.json\")\n",
        "\n",
        "print(\"\\n🎉 Results packaged in 'ecg_llm_training_results.zip'\")\n",
        "\n",
        "# Show file sizes\n",
        "result_files = ['ecg_llm_training_results.zip', 'best_model.pth']\n",
        "print(\"\\n📊 File Sizes:\")\n",
        "for file in result_files:\n",
        "    if os.path.exists(file):\n",
        "        size_mb = os.path.getsize(file) / (1024 * 1024)\n",
        "        print(f\"  {file}: {size_mb:.2f} MB\")\n",
        "\n",
        "print(\"\\n📥 You can download these files from the Files panel (📁) on the left.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "## 🎯 Next Steps and Recommendations\n",
        "\n",
        "### 🚀 **Your ECG-LLM Model is Now Trained!**\n",
        "\n",
        "### **What You Have:**\n",
        "- ✅ Trained ECG classification model\n",
        "- ✅ PQRST wave detection capabilities  \n",
        "- ✅ Validated on real clinical data (PTB-XL)\n",
        "- ✅ Google Drive backup of all results\n",
        "- ✅ Ready-to-deploy model files\n",
        "\n",
        "### **Performance Improvements:**\n",
        "1. **Increase Dataset Size**: Use full PTB-XL (21K+ records)\n",
        "2. **Advanced Augmentation**: Add noise, scaling, temporal shifts\n",
        "3. **Ensemble Methods**: Combine multiple model architectures\n",
        "4. **Transfer Learning**: Fine-tune on specific cardiac conditions\n",
        "\n",
        "### **Deployment Options:**\n",
        "1. **Local Deployment**:\n",
        "   ```python\n",
        "   # Load trained model\n",
        "   model = torch.load('best_model.pth')\n",
        "   ```\n",
        "\n",
        "2. **Cloud Deployment**:\n",
        "   - AWS SageMaker\n",
        "   - Google Cloud AI Platform\n",
        "   - Azure ML\n",
        "\n",
        "3. **Edge Deployment**:\n",
        "   - Convert to ONNX/TensorRT\n",
        "   - Mobile optimization\n",
        "   - IoT device deployment\n",
        "\n",
        "### **Clinical Applications:**\n",
        "- 🏥 Hospital ECG screening\n",
        "- 📱 Mobile health monitoring\n",
        "- 🔬 Research tool for cardiologists\n",
        "- 📊 Population health studies\n",
        "\n",
        "### **Continue Development:**\n",
        "- Implement attention mechanisms\n",
        "- Add uncertainty quantification\n",
        "- Create explainable AI features\n",
        "- Validate on additional datasets\n",
        "\n",
        "**🎉 Congratulations! You've successfully trained an advanced ECG analysis model using your own codebase on Google Colab Pro!**"
      ]
    }
  ]
}