{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸ«€ ECG-LLM Training Runner for GitHub Sync\n",
    "\n",
    "This notebook runs your ECG-LLM code from GitHub on Colab GPU.\n",
    "\n",
    "**Workflow:**\n",
    "1. Develop in Windsurf locally\n",
    "2. Push to GitHub\n",
    "3. Run this notebook in Colab for GPU training\n",
    "4. Results auto-save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu_check"
   },
   "outputs": [],
   "source": [
    "# Check GPU setup\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"ğŸ”¥ PyTorch: {torch.__version__}\")\n",
    "print(f\"ğŸ–¥ï¸  CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸš€ GPU: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Available storage:\")\n",
    "!df -h | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install wfdb neurokit2 pandas numpy matplotlib seaborn\n",
    "!pip install opencv-python scikit-learn tqdm\n",
    "!pip install transformers timm efficientnet-pytorch\n",
    "!pip install Pillow\n",
    "\n",
    "print(\"âœ… All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": "# Clone your GitHub repository\n# Your GitHub repo URL\nGITHUB_REPO = \"https://github.com/Anjaniputra15/ECG-Final.git\"\n\nimport os\nif os.path.exists('ECG-Final'):\n    print(\"ğŸ“ Repository already exists, pulling latest changes...\")\n    %cd ECG-Final\n    !git pull\nelse:\n    print(\"ğŸ“¥ Cloning repository...\")\n    !git clone {GITHUB_REPO}\n    %cd ECG-Final\n\nprint(\"\\nğŸ“‚ Repository contents:\")\n!ls -la"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_drive"
   },
   "outputs": [],
   "source": [
    "# Setup Google Drive for results\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create results directory\n",
    "results_dir = '/content/drive/MyDrive/ECG_Training_Results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(f'{results_dir}/models', exist_ok=True)\n",
    "os.makedirs(f'{results_dir}/experiments', exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Results will be saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_data"
   },
   "outputs": [],
   "source": [
    "# Download PTB-XL dataset (only run once)\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "data_dir = \"data\"\n",
    "dataset_name = \"ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3\"\n",
    "\n",
    "if not os.path.exists(f\"{data_dir}/{dataset_name}\"):\n",
    "    print(\"ğŸ“¥ Downloading PTB-XL dataset (this takes 5-10 minutes)...\")\n",
    "    \n",
    "    url = \"https://physionet.org/static/published-projects/ptb-xl/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3.zip\"\n",
    "    \n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # Download\n",
    "    urllib.request.urlretrieve(url, \"ptb-xl.zip\")\n",
    "    print(\"âœ… Download complete!\")\n",
    "    \n",
    "    # Extract\n",
    "    print(\"ğŸ“¦ Extracting dataset...\")\n",
    "    with zipfile.ZipFile(\"ptb-xl.zip\", 'r') as zipf:\n",
    "        zipf.extractall(data_dir)\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(\"ptb-xl.zip\")\n",
    "    print(\"âœ… Dataset ready!\")\n",
    "else:\n",
    "    print(\"âœ… PTB-XL dataset already available!\")\n",
    "\n",
    "# Verify dataset\n",
    "dataset_path = f\"{data_dir}/{dataset_name}\"\n",
    "if os.path.exists(f\"{dataset_path}/ptbxl_database.csv\"):\n",
    "    import pandas as pd\n",
    "    db = pd.read_csv(f\"{dataset_path}/ptbxl_database.csv\")\n",
    "    print(f\"ğŸ“Š Dataset verified: {len(db):,} ECG records\")\nelse:\n",
    "    print(\"âŒ Dataset verification failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_bootstrap"
   },
   "outputs": [],
   "source": [
    "# Run bootstrap training (Phase 1)\n",
    "print(\"ğŸš€ Starting Bootstrap R-Peak Training...\")\n",
    "\n",
    "# Your bootstrap trainer adapted for Colab\n",
    "!python bootstrap_trainer.py --device cuda --batch-size 16 --epochs 25 --output-dir {results_dir}/bootstrap\n",
    "\n",
    "print(\"âœ… Bootstrap training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_advanced"
   },
   "outputs": [],
   "source": [
    "# Run advanced training (Phase 2)\n",
    "print(\"ğŸš€ Starting Advanced Multi-Model Training...\")\n",
    "\n",
    "# Your advanced trainer\n",
    "!python training/advanced_trainer.py --model-type ensemble --device cuda --epochs 50 --batch-size 8 --output-dir {results_dir}/advanced\n",
    "\n",
    "print(\"âœ… Advanced training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_results"
   },
   "outputs": [],
   "source": "# Save all results to Google Drive + Completion Notification\nimport shutil\nfrom datetime import datetime\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nsession_dir = f\"{results_dir}/training_session_{timestamp}\"\nos.makedirs(session_dir, exist_ok=True)\n\nprint(\"ğŸ’¾ Saving results to Google Drive...\")\n\n# Save models\nmodel_files = [\"best_model.pth\", \"latest_checkpoint.pth\"]\nfor model_file in model_files:\n    if os.path.exists(model_file):\n        shutil.copy2(model_file, f\"{session_dir}/{model_file}\")\n        print(f\"âœ… Saved {model_file}\")\n\n# Save experiments\nif os.path.exists(\"experiments\"):\n    shutil.copytree(\"experiments\", f\"{session_dir}/experiments\", dirs_exist_ok=True)\n    print(\"âœ… Saved experiments\")\n\n# Save any plots/results\nresult_patterns = [\"*.png\", \"*.jpg\", \"*.json\", \"training_*.csv\"]\nimport glob\nfor pattern in result_patterns:\n    files = glob.glob(pattern)\n    for file in files:\n        shutil.copy2(file, f\"{session_dir}/{file}\")\n        print(f\"âœ… Saved {file}\")\n\n# Create completion notification file\ncompletion_info = {\n    \"status\": \"TRAINING_COMPLETE\",\n    \"timestamp\": timestamp,\n    \"session_directory\": session_dir,\n    \"completion_time\": datetime.now().isoformat(),\n    \"message\": \"ğŸ‰ ECG-LLM training completed successfully! Check Google Drive for results.\"\n}\n\nimport json\nwith open(f\"{session_dir}/TRAINING_COMPLETE.json\", \"w\") as f:\n    json.dump(completion_info, f, indent=2)\n\n# Also save to main Drive folder for easy finding\nwith open(f\"{results_dir}/LATEST_TRAINING_STATUS.json\", \"w\") as f:\n    json.dump(completion_info, f, indent=2)\n\nprint(f\"\\nğŸ‰ All results saved to: {session_dir}\")\nprint(\"ğŸ”” Training completion notification saved!\")\nprint(\"ğŸŒ™ You can safely sleep - results are in Google Drive!\")\nprint(f\"ğŸ“± Check {results_dir}/LATEST_TRAINING_STATUS.json for completion status\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_model"
   },
   "outputs": [],
   "source": [
    "# Quick model test\n",
    "print(\"ğŸ§ª Testing trained model...\")\n",
    "\n",
    "if os.path.exists(\"test_real_data.py\"):\n",
    "    !python test_real_data.py --model-path best_model.pth --num-samples 5\nelse:\n",
    "    print(\"âš ï¸  Test script not found, skipping model test\")\n",
    "\n",
    "print(\"âœ… Testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## ğŸ¯ Training Complete!\n",
    "\n",
    "Your ECG-LLM model has been trained on Google Colab GPU using your latest Windsurf code.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Check Google Drive for your training results\n",
    "2. Download the best model for local testing\n",
    "3. Continue development in Windsurf\n",
    "4. Push updates and re-run this notebook as needed\n",
    "\n",
    "**Perfect Workflow:**\n",
    "- ğŸ’» Develop in Windsurf (fast, local)\n",
    "- ğŸš€ Train on Colab (GPU power)\n",
    "- ğŸ—‚ï¸ Results in Drive (persistent)\n",
    "- ğŸ”„ Repeat and iterate!\n"
   ]
  }
 ]
}